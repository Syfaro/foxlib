//! Type-safe interface for Faktory.

use std::{
    borrow::Cow,
    collections::HashMap,
    error::Error as StdError,
    future::Future,
    net::TcpStream,
    sync::{Arc, Mutex},
};

pub use faktory::Job as FaktoryJob;
use lazy_static::lazy_static;
use prometheus::{register_counter_vec, register_histogram_vec, CounterVec, HistogramVec};
use tracing::{instrument, Instrument};

lazy_static! {
    static ref JOB_EXECUTION_TIME: HistogramVec = register_histogram_vec!(
        "forge_job_duration_seconds",
        "Duration to complete a job.",
        &["job"]
    )
    .unwrap();
    static ref JOB_FAILURE_COUNT: CounterVec = register_counter_vec!(
        "forge_job_failure_total",
        "Number of job failures",
        &["job"]
    )
    .unwrap();
}

/// An error generated by a job handler.
pub trait ForgeError
where
    Self: StdError + From<serde_json::Error>,
{
    /// If the job should be retried by Faktory.
    fn is_retryable(&self) -> bool;
}

/// A single or dynamic collection of queues for a job.
pub trait JobQueue {
    /// The name of the queue this job should be placed on.
    fn queue_name(&self) -> Cow<'static, str>;
}

/// A job that can be created and run.
pub trait Job
where
    Self: Sized,
{
    /// Name of the job, as sent to Faktory.
    const NAME: &'static str;

    /// The data associated with the job.
    type Data;
    /// The queue associated with the job.
    type Queue: JobQueue;

    /// Which queue this job will be performed on.
    fn queue(&self) -> Self::Queue;
    /// Extra data associated with the job.
    fn extra(&self) -> Result<Option<JobExtra>, serde_json::Error>;

    /// Arguments associated with the job.
    fn args(self) -> Result<Vec<serde_json::Value>, serde_json::Error>;
    /// Used to convert job arguments back into `Data`.
    fn deserialize(args: Vec<serde_json::Value>) -> Result<Self::Data, serde_json::Error>;

    /// Register a handler for a job.
    fn register<C, E, F, Fut>(forge: &mut FaktoryForge<C, E>, handler: F)
    where
        C: 'static + Send + Sync + Clone,
        E: 'static + ForgeError,
        F: 'static + Send + Sync + Fn(C, FaktoryJob, Self::Data) -> Fut,
        Fut: Future<Output = Result<(), E>>,
    {
        forge.register::<Self, Self::Queue, _, _>(handler)
    }

    /// Convert this job to a Faktory job.
    fn job(self) -> Result<FaktoryJob, serde_json::Error> {
        let queue = self.queue().queue_name();
        let custom = job_custom(self.extra()?.unwrap_or_default());
        let args = self.args()?;

        let mut job = FaktoryJob::new(Self::NAME, args).on_queue(queue.as_ref());
        job.custom = custom;

        Ok(job)
    }
}

/// Middleware that runs before a job is given to a handler and after a handler
/// has finished executing.
pub trait FaktoryForgeMiddleware<C, E> {
    /// Code to execute before job is given to handler.
    ///
    /// This might be useful in order to modify the job, perform logging, or
    /// return an error before the handler is invoked.
    fn before_request(&self, context: C, job: FaktoryJob) -> Result<FaktoryJob, E>;

    /// Code to execute after a job has been executed by a handler.
    ///
    /// This might be useful in order to modify the result or perform logging.
    fn after_request(&self, context: C, duration: f64, result: Result<(), E>) -> Result<(), E>;
}

/// Collection of middlewares.
pub type Middlewares<C, E> = Vec<Box<dyn FaktoryForgeMiddleware<C, E> + Send + Sync>>;

/// Forge used to register handlers for Faktory jobs.
pub struct FaktoryForge<C, E> {
    consumer_builder: faktory::ConsumerBuilder<E>,
    rt: tokio::runtime::Handle,
    middlewares: Arc<Middlewares<C, E>>,
    context: C,
}

impl<C, E> FaktoryForge<C, E>
where
    C: 'static + Send + Sync + Clone,
    E: 'static + ForgeError,
{
    /// Create a new forge to register job handlers.
    pub async fn new(context: C, middlewares: Option<Middlewares<C, E>>) -> Self {
        let consumer_builder = faktory::ConsumerBuilder::default();
        let rt = tokio::runtime::Handle::current();

        Self {
            consumer_builder,
            rt,
            context,
            middlewares: Arc::new(middlewares.unwrap_or_default()),
        }
    }

    /// Register a handler for a job.
    pub fn register<J, Q, F, Fut>(&mut self, f: F)
    where
        J: Job,
        Q: JobQueue,
        F: 'static + Send + Sync + Fn(C, FaktoryJob, J::Data) -> Fut,
        Fut: Future<Output = Result<(), E>>,
    {
        tracing::info!(name = J::NAME, "registering handler");

        let rt = self.rt.clone();
        let context = self.context.clone();
        let middlewares = self.middlewares.clone();

        let handler = move |job: FaktoryJob| -> Result<(), E> {
            let span = tracing::info_span!("faktory_job", name = J::NAME, queue = %job.queue, job_id = %job.id());

            let cx = Self::extract_context(&job);
            tracing_opentelemetry::OpenTelemetrySpanExt::set_parent(&span, cx);

            let _guard = span.entered();

            tracing::debug!("running job handler");

            let job = middlewares.iter().try_fold(job, |job, middleware| {
                middleware.before_request(context.clone(), job)
            })?;

            let data = J::deserialize(job.args().to_owned())?;

            let execution_timer = JOB_EXECUTION_TIME
                .with_label_values(&[J::NAME])
                .start_timer();
            let result = rt.block_on(f(context.clone(), job, data).in_current_span());
            let execution_time = execution_timer.stop_and_record();

            let result = middlewares.iter().fold(result, |result, middleware| {
                middleware.after_request(context.clone(), execution_time, result)
            });

            if let Err(ref err) = result {
                tracing::error!(
                    is_retryable = err.is_retryable(),
                    execution_time,
                    "completed job handler with error: {}",
                    err
                );
            } else {
                tracing::info!(execution_time, "completed job handler successfully");
            };

            if matches!(result, Err(ref err) if err.is_retryable()) {
                result
            } else {
                Ok(())
            }
        };

        self.consumer_builder.register(J::NAME, handler);
    }

    /// Finalize forge and return a `faktory::ConsumerBuilder` which can be
    /// configured and then connected.
    pub fn finalize(self) -> faktory::ConsumerBuilder<E> {
        self.consumer_builder
    }

    /// Extract an OpenTelemetry context from a job.
    fn extract_context(job: &FaktoryJob) -> opentelemetry::Context {
        let custom_strings: HashMap<String, String> = job
            .custom
            .iter()
            .flat_map(|(name, value)| {
                value
                    .as_str()
                    .map(|value| (name.to_owned(), value.to_owned()))
            })
            .collect();

        opentelemetry::global::get_text_map_propagator(|propagator| {
            propagator.extract(&custom_strings)
        })
    }
}

/// Extra data associated with a job.
pub type JobExtra = HashMap<String, serde_json::Value>;

/// Error encountered when trying to interact with Faktory.
#[derive(Debug, thiserror::Error)]
pub enum Error {
    /// An error when interacting with Faktory.
    #[error("faktory error: {0}")]
    Faktory(#[from] faktory::Error),
    /// An error when trying to work with Tokio's tasks.
    #[error("join error: {0}")]
    Join(#[from] tokio::task::JoinError),
    /// An error when trying to serialize or deserialize JSON data.
    #[error("json error: {0}")]
    Json(#[from] serde_json::Error),
}

/// Faktory producer used to enqueue new jobs.
#[derive(Clone)]
pub struct FaktoryProducer {
    client: Arc<Mutex<faktory::Producer<TcpStream>>>,
}

impl FaktoryProducer {
    /// Connect to a given Faktory instance.
    pub async fn connect(url: Option<String>) -> Result<Self, Error> {
        let producer =
            tokio::task::spawn_blocking(move || faktory::Producer::connect(url.as_deref()))
                .in_current_span()
                .await??;

        Ok(Self {
            client: Arc::new(Mutex::new(producer)),
        })
    }

    /// Enqueue a new job to be as run as soon as possible.
    #[inline]
    pub fn enqueue_job<'a, J>(&'a self, job: J) -> impl Future<Output = Result<String, Error>> + 'a
    where
        J: 'a + Job,
    {
        self.enqueue_job_at(job, None)
    }

    /// Enqueue a new job to be run at an optionally provided time.
    #[instrument(err, skip(self, job, at), fields(job_id, name, queue))]
    pub async fn enqueue_job_at<J>(
        &self,
        job: J,
        at: Option<chrono::DateTime<chrono::Utc>>,
    ) -> Result<String, Error>
    where
        J: Job,
    {
        let mut job = job.job()?;
        job.at = at;

        let job_id = job.id().to_owned();

        tracing::Span::current()
            .record("name", J::NAME)
            .record("queue", &job.queue)
            .record("job_id", &job_id);

        tracing::debug!("attempting to enqueue job with args {:?}", job.args());

        self.enqueue_existing_job(job).await?;

        tracing::info!("enqueued job");

        Ok(job_id)
    }

    /// Enqueue a job that was already converted to a `FaktoryJob`.
    pub async fn enqueue_existing_job(&self, job: FaktoryJob) -> Result<(), Error> {
        let client = self.client.clone();
        tokio::task::spawn_blocking(move || {
            let mut client = client.lock().expect("faktory client was poisoned");
            client.enqueue(job)
        })
        .in_current_span()
        .await??;

        Ok(())
    }
}

/// Collect extra data to attach to the job.
pub fn job_custom(existing: JobExtra) -> JobExtra {
    tracing_headers()
        .into_iter()
        .map(|(name, value)| (name, serde_json::Value::from(value)))
        .chain(existing)
        .collect()
}

/// Get tracing headers to associate with the job.
pub fn tracing_headers() -> HashMap<String, String> {
    use tracing_opentelemetry::OpenTelemetrySpanExt;

    let mut headers = HashMap::with_capacity(2);
    let cx = tracing::Span::current().context();

    opentelemetry::global::get_text_map_propagator(|propagator| {
        propagator.inject_context(&cx, &mut headers)
    });

    headers
}
